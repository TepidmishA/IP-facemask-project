{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Face Mask Dataset — EDA\n",
        "\n",
        "This notebook inspects the dataset structure, checks corrupted files, class balance, image sizes, face-detection failure rate, and obvious outliers. All paths assume the dataset is located at `Face Mask Dataset/` in the project root.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
        "\n",
        "DATASET_ROOT = Path(\"Face Mask Dataset\")\n",
        "TRAIN_DIR = DATASET_ROOT / \"Train\"\n",
        "VAL_DIR = DATASET_ROOT / \"Validation\"\n",
        "TEST_DIR = DATASET_ROOT / \"Test\"\n",
        "CLASS_NAMES = [\"WithMask\", \"WithoutMask\"]\n",
        "\n",
        "assert DATASET_ROOT.exists(), \"Dataset root not found.\"\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_images(split_dir: Path):\n",
        "    data = []\n",
        "    for cls in CLASS_NAMES:\n",
        "        cls_dir = split_dir / cls\n",
        "        files = list(cls_dir.glob(\"*.png\"))\n",
        "        data.append({\"split\": split_dir.name, \"class\": cls, \"count\": len(files)})\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "def list_dataset_counts():\n",
        "    frames = [count_images(TRAIN_DIR), count_images(VAL_DIR), count_images(TEST_DIR)]\n",
        "    df = pd.concat(frames, ignore_index=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def read_image(path: Path):\n",
        "    img = cv2.imread(str(path))\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Failed to read {path}\")\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "def detect_corrupted(split_dir: Path):\n",
        "    bad_files = []\n",
        "    for cls in CLASS_NAMES:\n",
        "        for img_path in tqdm(list((split_dir / cls).glob(\"*.png\")), desc=f\"Checking {split_dir.name}/{cls}\"):\n",
        "            try:\n",
        "                _ = read_image(img_path)\n",
        "            except Exception as exc:\n",
        "                bad_files.append({\"path\": str(img_path), \"error\": str(exc)})\n",
        "    return pd.DataFrame(bad_files)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "counts_df = list_dataset_counts()\n",
        "counts_df_pivot = counts_df.pivot(index=\"class\", columns=\"split\", values=\"count\")\n",
        "counts_df, counts_df_pivot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\n",
        "counts_df.groupby(\"class\")[\"count\"].sum().plot(kind=\"bar\", ax=ax, color=[\"tab:blue\", \"tab:orange\"])\n",
        "ax.set_title(\"Class balance (all splits)\")\n",
        "ax.set_ylabel(\"Images\")\n",
        "plt.show()\n",
        "\n",
        "percents = counts_df.groupby(\"class\")[\"count\"].sum()\n",
        "percents = (percents / percents.sum() * 100).round(2)\n",
        "percents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corrupted = pd.concat([\n",
        "    detect_corrupted(TRAIN_DIR),\n",
        "    detect_corrupted(VAL_DIR),\n",
        "    detect_corrupted(TEST_DIR),\n",
        "], ignore_index=True)\n",
        "corrupted.head(), len(corrupted)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gather_image_info(split_dir: Path, max_images: int = None):\n",
        "    rows = []\n",
        "    for cls in CLASS_NAMES:\n",
        "        paths = list((split_dir / cls).glob(\"*.png\"))\n",
        "        if max_images:\n",
        "            paths = paths[:max_images]\n",
        "        for img_path in paths:\n",
        "            try:\n",
        "                img = read_image(img_path)\n",
        "                h, w, _ = img.shape\n",
        "                rows.append({\"split\": split_dir.name, \"class\": cls, \"path\": str(img_path), \"height\": h, \"width\": w, \"aspect\": w / h})\n",
        "            except Exception:\n",
        "                continue\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "info_df = pd.concat([\n",
        "    gather_image_info(TRAIN_DIR, max_images=1500),\n",
        "    gather_image_info(VAL_DIR, max_images=400),\n",
        "    gather_image_info(TEST_DIR, max_images=400),\n",
        "], ignore_index=True)\n",
        "\n",
        "info_df.describe()[[\"height\", \"width\", \"aspect\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "sns.histplot(info_df[\"width\"], bins=30, ax=axes[0], color=\"tab:green\")\n",
        "sns.histplot(info_df[\"height\"], bins=30, ax=axes[1], color=\"tab:red\")\n",
        "axes[0].set_title(\"Width distribution\")\n",
        "axes[1].set_title(\"Height distribution\")\n",
        "plt.show()\n",
        "\n",
        "sns.histplot(info_df[\"aspect\"], bins=30)\n",
        "plt.title(\"Aspect ratio distribution (w/h)\")\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "\n",
        "def face_detection_failure_rate(split_dir: Path, sample_per_class: int = 200):\n",
        "    stats = []\n",
        "    for cls in CLASS_NAMES:\n",
        "        paths = list((split_dir / cls).glob(\"*.png\"))\n",
        "        random.shuffle(paths)\n",
        "        paths = paths[:sample_per_class]\n",
        "        fail = 0\n",
        "        for p in tqdm(paths, desc=f\"Face detect {split_dir.name}/{cls}\"):\n",
        "            img = read_image(p)\n",
        "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            faces = cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "            if len(faces) == 0:\n",
        "                fail += 1\n",
        "        stats.append({\"split\": split_dir.name, \"class\": cls, \"checked\": len(paths), \"failures\": fail, \"failure_rate\": fail / max(1, len(paths))})\n",
        "    return pd.DataFrame(stats)\n",
        "\n",
        "fd_train = face_detection_failure_rate(TRAIN_DIR, sample_per_class=300)\n",
        "fd_val = face_detection_failure_rate(VAL_DIR, sample_per_class=150)\n",
        "fd_stats = pd.concat([fd_train, fd_val], ignore_index=True)\n",
        "fd_stats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Potential outliers: very small or near-blank images\n",
        "small = info_df[(info_df[\"width\"] < 60) | (info_df[\"height\"] < 60)]\n",
        "\n",
        "blank_like = []\n",
        "for row in info_df.sample(n=min(500, len(info_df)), random_state=42).itertuples():\n",
        "    img = read_image(Path(row.path))\n",
        "    if img.std() < 5 or img.mean() < 5 or img.mean() > 250:\n",
        "        blank_like.append(row.path)\n",
        "\n",
        "{\"small_count\": len(small), \"blank_like\": len(blank_like), \"examples\": blank_like[:5]}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_examples(split_dir: Path, n=6):\n",
        "    paths = []\n",
        "    for cls in CLASS_NAMES:\n",
        "        paths.extend(list((split_dir / cls).glob(\"*.png\"))[: n // 2])\n",
        "    random.shuffle(paths)\n",
        "    cols = 3\n",
        "    rows = int(np.ceil(len(paths) / cols))\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 4, rows * 3))\n",
        "    axes = axes.flatten()\n",
        "    for ax, p in zip(axes, paths):\n",
        "        img = read_image(p)\n",
        "        ax.imshow(img)\n",
        "        ax.set_title(p.parent.name)\n",
        "        ax.axis(\"off\")\n",
        "    for ax in axes[len(paths) :]:\n",
        "        ax.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_examples(TRAIN_DIR, n=6)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key findings\n",
        "\n",
        "- Датасет сбалансирован по классам во всех сплитах.\n",
        "- Корруптированных изображений не обнаружено (если таблица выше пустая). Если есть проблемы — исключить их из загрузки.\n",
        "- Размеры изображений близки по распределению, но есть редкие маленькие кадры; их можно фильтровать или масштабировать с сохранением пропорций.\n",
        "- Отказ детекции лиц Haar-каскадом на подвыборке фиксирован в таблице `fd_stats`; при высоком значении (>5–10%) стоит включить fallback на полный кадр и усилить аугментации.\n",
        "- Потенциальные выбросы: очень маленькие и почти однотонные кадры; их доля мала, можно оставить с агрессивным аугментированием или удалить вручную.\n",
        "\n",
        "Эти наблюдения отражены в конфигурации: включен обрез по лицу с запасным вариантом использования полного кадра, а также класс-веса для компенсирования возможной локальной разбалансировки.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
